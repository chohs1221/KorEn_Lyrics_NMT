{"cells":[{"cell_type":"markdown","source":["# Import Requirements"],"metadata":{}},{"cell_type":"code","execution_count":3,"source":["#%%\r\n","import os\r\n","import random\r\n","import gc\r\n","from typing import Dict, List\r\n","import csv\r\n","\r\n","from easydict import EasyDict as edict\r\n","\r\n","import wandb\r\n","\r\n","import numpy as np\r\n","\r\n","import torch\r\n","\r\n","from lib.tokenization_kobert import KoBertTokenizer\r\n","from transformers import (\r\n","    EncoderDecoderModel,\r\n","    GPT2Tokenizer as BaseGPT2Tokenizer,\r\n","    DataCollatorForSeq2Seq,\r\n","    Seq2SeqTrainingArguments,\r\n","    Trainer,\r\n",")"],"outputs":[],"metadata":{"executionInfo":{"elapsed":3691,"status":"ok","timestamp":1650707183988,"user":{"displayName":"조현수","userId":"06575509224308139266"},"user_tz":-540},"id":"vdvX4ArkUoR0"}},{"cell_type":"markdown","source":["# Make Dir"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["#%%\r\n","for name in ('checkpoints',):\r\n","    os.makedirs(name, exist_ok=True)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["# Set Arguments"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["#%%\r\n","args = edict({'w_project': 'test_project',\r\n","              'w_entity': 'chohs1221',\r\n","              'pretraining': False,\r\n","              'learning_rate': 1e-4,\r\n","              'batch_size': {'train': 8,\r\n","                             'eval': 4,},\r\n","              'accumulate': 32,\r\n","              'epochs': 15,\r\n","              'seed': 42,\r\n","              'model_path': {'encoder': 'monologg/distilkobert',\r\n","                            'decoder': 'distilgpt2'},\r\n","              })\r\n","\r\n","if args.pretraining:\r\n","    args['NAME'] = f'kobert_gpt2_ep{args.epochs}_lr{args.learning_rate}_{random.randrange(100, 1000)}_pre'\r\n","else:\r\n","    args['NAME'] = f'kobert_gpt2_ep{args.epochs}_lr{args.learning_rate}_{random.randrange(100, 1000)}_fine'\r\n","print(args.NAME)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["# Random Seed"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["#%%\r\n","def seed_everything(seed):\r\n","    random.seed(seed)\r\n","    np.random.seed(seed)\r\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\r\n","    torch.manual_seed(seed)\r\n","    torch.cuda.manual_seed(seed)  # type: ignore\r\n","    torch.backends.cudnn.deterministic = True  # type: ignore\r\n","    torch.backends.cudnn.benchmark = True  # type: ignore\r\n","\r\n","seed_everything(args.seed)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["# Wandb Settings"],"metadata":{}},{"cell_type":"code","execution_count":4,"source":["#%%\r\n","wandb.login()\r\n","\r\n","wandb.init(project = args.w_project, entity = args.w_entity)\r\n","wandb.run.name = args.NAME"],"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchohs1221\u001b[0m (use `wandb login --relogin` to force relogin)\n"]},{"output_type":"display_data","data":{"text/html":["Tracking run with wandb version 0.12.15"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/goorm_project3/wandb/run-20220423_094624-1khu6h63</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["Syncing run <strong><a href=\"https://wandb.ai/chohs1221/test_project/runs/1khu6h63\" target=\"_blank\">floral-jazz-27</a></strong> to <a href=\"https://wandb.ai/chohs1221/test_project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/chohs1221/test_project/runs/1khu6h63?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7f878b1350d0>"]},"metadata":{},"execution_count":4}],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":110},"executionInfo":{"elapsed":4329,"status":"ok","timestamp":1650707188311,"user":{"displayName":"조현수","userId":"06575509224308139266"},"user_tz":-540},"id":"iKYy4ObPwuNG","outputId":"b3d3bc0b-e44a-412d-8c2f-c783ae94f10f"}},{"cell_type":"markdown","source":["# Load Tokenizer"],"metadata":{}},{"cell_type":"code","execution_count":5,"source":["#%%\r\n","class GPT2Tokenizer(BaseGPT2Tokenizer):\r\n","    def build_inputs_with_special_tokens(self, token_ids: List[int], _) -> List[int]:\r\n","        return token_ids + [self.eos_token_id]"],"outputs":[],"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1650707188312,"user":{"displayName":"조현수","userId":"06575509224308139266"},"user_tz":-540},"id":"-xPy4nK1xX7_"}},{"cell_type":"code","execution_count":6,"source":["#%%\r\n","# enc_tokenizer = KoBertTokenizer.from_pretrained(args.model_path.encoder)\r\n","enc_tokenizer = KoBertTokenizer.from_pretrained('monologg/kobert')\r\n","dec_tokenizer = GPT2Tokenizer.from_pretrained(args.model_path.decoder)"],"outputs":[{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n","The class this function is called from is 'KoBertTokenizer'.\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1873,"status":"ok","timestamp":1650707190180,"user":{"displayName":"조현수","userId":"06575509224308139266"},"user_tz":-540},"id":"PTkupFxSz4M9","outputId":"d2363f25-8bee-4059-c286-0c1e4416aa4f"}},{"cell_type":"markdown","source":["# Load Model"],"metadata":{}},{"cell_type":"code","execution_count":7,"source":["# %%\r\n","if args.pretraining:\r\n","    model = EncoderDecoderModel.from_encoder_decoder_pretrained(\r\n","        args.model_path.encoder,\r\n","        args.model_path.decoder,    \r\n","        pad_token_id=dec_tokenizer.bos_token_id\r\n","    )\r\n","    model.config.decoder_start_token_id = dec_tokenizer.bos_token_id\r\n","else:\r\n","    model = EncoderDecoderModel.from_pretrained(f'./checkpoints/bertgpt2_ep10_lr0.0001_753_pre')"],"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at distilgpt2 and are newly initialized: ['transformer.h.5.crossattention.masked_bias', 'transformer.h.0.crossattention.c_attn.weight', 'transformer.h.5.crossattention.bias', 'transformer.h.2.crossattention.c_proj.weight', 'transformer.h.2.crossattention.bias', 'transformer.h.4.crossattention.masked_bias', 'transformer.h.5.ln_cross_attn.weight', 'transformer.h.2.ln_cross_attn.weight', 'transformer.h.5.crossattention.c_proj.weight', 'transformer.h.3.ln_cross_attn.weight', 'transformer.h.5.crossattention.c_proj.bias', 'transformer.h.4.crossattention.c_proj.weight', 'transformer.h.0.crossattention.bias', 'transformer.h.4.ln_cross_attn.weight', 'transformer.h.2.crossattention.q_attn.weight', 'transformer.h.1.crossattention.bias', 'transformer.h.1.crossattention.c_proj.weight', 'transformer.h.3.crossattention.masked_bias', 'transformer.h.0.crossattention.c_proj.weight', 'transformer.h.0.ln_cross_attn.weight', 'transformer.h.1.crossattention.q_attn.weight', 'transformer.h.4.crossattention.c_proj.bias', 'transformer.h.2.crossattention.c_proj.bias', 'transformer.h.4.crossattention.bias', 'transformer.h.0.crossattention.c_proj.bias', 'transformer.h.4.crossattention.q_attn.weight', 'transformer.h.5.crossattention.q_attn.weight', 'transformer.h.3.crossattention.c_proj.bias', 'transformer.h.5.crossattention.c_attn.weight', 'transformer.h.4.crossattention.c_attn.weight', 'transformer.h.1.ln_cross_attn.weight', 'transformer.h.3.crossattention.q_attn.weight', 'transformer.h.0.crossattention.masked_bias', 'transformer.h.3.crossattention.bias', 'transformer.h.0.crossattention.q_attn.weight', 'transformer.h.1.crossattention.c_proj.bias', 'transformer.h.3.crossattention.c_attn.weight', 'transformer.h.3.crossattention.c_proj.weight', 'transformer.h.2.crossattention.c_attn.weight', 'transformer.h.1.crossattention.masked_bias', 'transformer.h.2.crossattention.masked_bias', 'transformer.h.1.crossattention.c_attn.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2877,"status":"ok","timestamp":1650707193053,"user":{"displayName":"조현수","userId":"06575509224308139266"},"user_tz":-540},"id":"edRSIX52U0iw","outputId":"ff6a51ad-e6a7-46ea-fc6d-538509398949"}},{"cell_type":"markdown","source":["# Load Datasets"],"metadata":{}},{"cell_type":"code","execution_count":8,"source":["#%%\n","class PairedDataset:\n","    def __init__(self, data, enc_tokenizer=enc_tokenizer, dec_tokenizer=dec_tokenizer):\n","        self.data = data\n","\n","        self.enc_tokenizer = enc_tokenizer\n","        self.dec_tokenizer = dec_tokenizer\n","\n","    @classmethod\n","    def loads(cls, *file_names):\n","        data = []\n","        for file_name in file_names:\n","            if args.pretraining:\n","                with open(file_name, 'r', encoding='utf-8') as fd:\n","                    data += [row[1:] for row in csv.reader(fd)]\n","            else:\n","                with open(file_name, 'r', encoding='cp949') as fd:\n","                    data += [row[1:] for row in csv.reader(fd)]\n","        \n","        return cls(data)\n","    \n","    @classmethod\n","    def split(cls, datasets, ratio = 0.1):\n","        valid_length = int(len(datasets) * ratio)\n","        train = [datasets[i] for i in range(len(datasets) - valid_length)]\n","        valid = [datasets[i] for i in range(valid_length, len(datasets))]\n","\n","        return cls(train), cls(valid)\n","\n","    def __getitem__(self, index: int) -> List[str]:\n","        return self.data[index]\n","\n","    def __len__(self):\n","        return len(self.data)"],"outputs":[],"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1650707193053,"user":{"displayName":"조현수","userId":"06575509224308139266"},"user_tz":-540},"id":"rqPxz9Z2UuQT"}},{"cell_type":"code","execution_count":9,"source":["#%%\n","if args.pretraining:\n","    dataset = PairedDataset.loads('./data/train.csv', './data/dev.csv')\n","else:\n","    dataset = PairedDataset.loads('./data/kor2en_all.csv',)\n","train_dataset_, valid_dataset_ = PairedDataset.split(dataset)\n","print(train_dataset_[0])\n","print(valid_dataset_[0])"],"outputs":[{"output_type":"stream","name":"stdout","text":["['또 져버린 것 같아 넌 화가 나 보여 아른대는 Game over over over', 'I think I lost again You look mad In a blur, game over over over']\n","['어쩌면 난 너를 쉽게 잊을지 몰라. 혹시 너 아닌 다른 기억도 지워진다면. ', \"Maybe I'll easily forget you Maybe I'll erase all the other memories\"]\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1650707193054,"user":{"displayName":"조현수","userId":"06575509224308139266"},"user_tz":-540},"id":"qKE2dZFwUuNl","outputId":"ab2a948c-56b9-44c9-c963-5bdbb8fec983"}},{"cell_type":"markdown","source":["# Tokenize Datasets"],"metadata":{}},{"cell_type":"code","execution_count":10,"source":["#%%\n","class TokenizeDataset:\n","    def __init__(self, dataset, enc_tokenizer, dec_tokenizer):\n","        self.dataset = dataset\n","        self.enc_tokenizer = enc_tokenizer\n","        self.dec_tokenizer = dec_tokenizer\n","    \n","    def __getitem__(self, index: int):\n","        src, trg = self.dataset[index]\n","        input = self.enc_tokenizer(src, return_attention_mask=False, return_token_type_ids=False, truncation = True, max_length = 512)\n","        input['labels'] = self.dec_tokenizer(trg, return_attention_mask=False)['input_ids']\n","\n","        return input\n","    \n","    def __len__(self):\n","        return len(self.dataset)"],"outputs":[],"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1650707193055,"user":{"displayName":"조현수","userId":"06575509224308139266"},"user_tz":-540},"id":"S9iZ-Mypx4hU"}},{"cell_type":"code","execution_count":null,"source":["#%%\n","train_dataset = TokenizeDataset(train_dataset_, enc_tokenizer, dec_tokenizer)\n","valid_dataset = TokenizeDataset(valid_dataset_, enc_tokenizer, dec_tokenizer)\n","# print(train_dataset[0])\n","# print(enc_tokenizer.convert_ids_to_tokens(train_dataset[0]['input_ids']))\n","# print(dec_tokenizer.convert_ids_to_tokens(train_dataset[0]['labels']))"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1650707193055,"user":{"displayName":"조현수","userId":"06575509224308139266"},"user_tz":-540},"id":"8oLpWFdc2Po_","outputId":"0595f68d-f633-439e-a436-c5857e8be633"}},{"cell_type":"markdown","source":["# Trainer"],"metadata":{}},{"cell_type":"code","execution_count":12,"source":["# %%\n","collator = DataCollatorForSeq2Seq(enc_tokenizer, model)\n","\n","arguments = Seq2SeqTrainingArguments(\n","    output_dir='checkpoints',\n","    do_train=True,\n","    do_eval=True,\n","\n","    num_train_epochs=args.epochs,\n","    learning_rate = args.learning_rate,\n","    warmup_ratio=0.1,\n","\n","    save_strategy=\"epoch\",\n","    save_total_limit=2,\n","    evaluation_strategy=\"epoch\",\n","    load_best_model_at_end=True,\n","\n","    per_device_train_batch_size=args.batch_size.train,\n","    per_device_eval_batch_size=args.batch_size.eval,\n","    gradient_accumulation_steps=args.accumulate,\n","    dataloader_num_workers=1,\n","    fp16=True,\n","\n","    report_to='wandb',\n","    run_name='test2'\n",")\n","\n","trainer = Trainer(\n","    model,\n","    arguments,\n","    data_collator=collator,\n","    train_dataset=train_dataset,\n","    eval_dataset=valid_dataset\n",")"],"outputs":[{"output_type":"stream","name":"stderr","text":["Using amp half precision backend\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3631,"status":"ok","timestamp":1650707196673,"user":{"displayName":"조현수","userId":"06575509224308139266"},"user_tz":-540},"id":"AOK7UQ2vUuLq","outputId":"078c1aef-acc5-467c-d5cf-546d2e926358"}},{"cell_type":"markdown","source":["# Train"],"metadata":{}},{"cell_type":"code","execution_count":13,"source":["#%%\n","gc.collect()\n","torch.cuda.empty_cache()"],"outputs":[],"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1650707196674,"user":{"displayName":"조현수","userId":"06575509224308139266"},"user_tz":-540},"id":"ZHNwJE0E0CKR"}},{"cell_type":"code","execution_count":null,"source":["# %%\n","trainer.train()\n","model.save_pretrained(f\"checkpoints/{args.NAME}\")"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":350},"id":"JcMNh9jdUuJg","outputId":"9ad86ffd-0978-4207-826d-755a32b4af04"}},{"cell_type":"code","execution_count":null,"source":["#%%\n","wandb.finish()"],"outputs":[],"metadata":{"id":"qDB7_HZQUt8L"}},{"cell_type":"markdown","source":["# Predict"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["#%%\n","model = EncoderDecoderModel.from_pretrained(f'./checkpoints/{args.NAME}')\n","\n","input_prompt  = '집 가고 싶다'\n","input_ids = enc_tokenizer.encode(input_prompt, return_tensors='pt')\n","print(100 * '=' + \"\\nInput:\")\n","print(input_prompt)\n","outputs = model.generate(input_ids,\n","                        num_beams=5,\n","                        num_return_sequences=5,\n","                        max_length=50,\n","                        no_repeat_ngram_size = 2)\n","print(50 * '- ' + \"\\nOutput:\")\n","for i, output in enumerate(outputs):\n","  print(\"{}: {}\".format(i, dec_tokenizer.decode(output, skip_special_tokens=True)))\n","print(100*'=')"],"outputs":[],"metadata":{}}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMrHPOdk5I+1IlvYImTSHFB","background_execution":"on","collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1UkFQ8QNwx61mpLcku4dmX0mla9pxbnVb","name":"KoBERT_DistilGPT2_NMT.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":2}