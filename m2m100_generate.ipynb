{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "from typing import List\n",
    "\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "from transformers import(\n",
    "    M2M100ForConditionalGeneration,\n",
    "    M2M100Tokenizer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Trainer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "args = edict({'w_project': 'test_project',\n",
    "              'w_entity': 'chohs1221',\n",
    "              'pretraining': False,\n",
    "              'lang': 'en2kor',\n",
    "              'learning_rate': 1e-4,\n",
    "              'batch_size': {'train': 2,\n",
    "                             'eval': 4,},\n",
    "              'accumulate': 64,\n",
    "              'epochs': 15,\n",
    "              'seed': 42,\n",
    "              'model_path': 'facebook/m2m100_418M',\n",
    "              })\n",
    "\n",
    "if args.pretraining:\n",
    "    args['NAME'] = f'm2m100_ep{args.epochs}_lr{args.learning_rate}_{random.randrange(100, 1000)}_pre'\n",
    "else:\n",
    "    args['NAME'] = f'm2m100_ep{args.epochs}_lr{args.learning_rate}_{random.randrange(100, 1000)}_fine'\n",
    "print(args.NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "model = M2M100ForConditionalGeneration.from_pretrained(args.model_path)\n",
    "tokenizer = M2M100Tokenizer.from_pretrained(args.model_path)\n",
    "if args.lang == 'kor2en':\n",
    "    tokenizer.src_lang = \"ko\"\n",
    "    tokenizer.tgt_lang = \"en\"\n",
    "elif args.lang == 'en2kor':\n",
    "    tokenizer.src_lang = \"en\"\n",
    "    tokenizer.tgt_lang = \"ko\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "input_prompt  = 'let it go let it go'\n",
    "input_ids = tokenizer.encode(input_prompt, return_tensors='pt')\n",
    "print(100 * '=' + \"\\nInput:\")\n",
    "print(input_prompt)\n",
    "outputs = model.generate(input_ids,\n",
    "                        num_beams=5,\n",
    "                        num_return_sequences=5,\n",
    "                        max_length=50,\n",
    "                        no_repeat_ngram_size = 2,\n",
    "                        forced_bos_token_id=tokenizer.get_lang_id(\"ko\"))\n",
    "print(50 * '- ' + \"\\nOutput:\")\n",
    "for i, output in enumerate(outputs):\n",
    "  print(\"{}: {}\".format(i, tokenizer.batch_decode(output, skip_special_tokens=True)))\n",
    "print(100*'=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "23393d2575091a37cff0d0e9e7479591a295495b26c3b2ebf9b64da572e02d85"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
